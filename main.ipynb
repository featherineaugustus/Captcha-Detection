{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7680a79",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib  # to save/load model\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58027b1",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look through image folder\n",
    "image_folder = 'sampleCaptchas/input/'\n",
    "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dde81d",
   "metadata": {},
   "source": [
    "# Show Raw Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file_path = 'sampleCaptchas/output/'\n",
    "\n",
    "for img_name in image_files:\n",
    "    print(img_name)\n",
    "    text_file = img_name.replace('jpg', 'txt').replace('input', 'output')\n",
    "    with open(text_file_path + text_file, 'r') as f:\n",
    "        for line in f:\n",
    "            print(line.strip())\n",
    "        \n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Failed to load {img_name}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert from BGR to RGB for matplotlib\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(img_name)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21bfc3a",
   "metadata": {},
   "source": [
    "# Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dc189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, top=0, bottom=0, left=0, right=0):\n",
    "    \"\"\"\n",
    "    Crops a fixed number of pixels from the left and right sides of an image.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): The input image.\n",
    "        left_crop (int): Pixels to remove from the left.\n",
    "        right_crop (int): Pixels to remove from the right.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Cropped image.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    return img[top:h - bottom, left:w - right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_left_to_right(img, num_parts=5):\n",
    "    \"\"\"\n",
    "    Slice an image left-to-right into equal-width vertical slices.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): The input image.\n",
    "        num_parts (int): Number of left-to-right vertical slices.\n",
    "\n",
    "    Returns:\n",
    "        list of np.ndarray: List of sliced character images.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    part_width = w // num_parts\n",
    "    part_width = 9\n",
    "    slices = []\n",
    "\n",
    "    for i in range(num_parts):\n",
    "        x_start = i * part_width\n",
    "        x_end = (i + 1) * part_width\n",
    "        slice_img = img[:, x_start:x_end]  # all rows, columns i\n",
    "        slices.append(slice_img)\n",
    "\n",
    "    return slices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc59b88",
   "metadata": {},
   "source": [
    "# Isolate images into individual characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file_path = 'sampleCaptchas/output/'\n",
    "\n",
    "counter = 1\n",
    "data = []\n",
    "for img_name in image_files:\n",
    "    print(img_name)\n",
    "    text_file = img_name.replace('jpg', 'txt').replace('input', 'output')\n",
    "    with open(text_file_path + text_file, 'r') as f:\n",
    "        for line in f:\n",
    "            print(line.strip())\n",
    "        \n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = crop_image(img, top=11, bottom=9, left=5, right=11)\n",
    "    _, img = cv2.threshold(img, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "    img = cv2.bitwise_not(img)\n",
    "    \n",
    "    parts = slice_left_to_right(img)\n",
    "\n",
    "    # Display the 5 vertical slices\n",
    "    for i, part in enumerate(parts):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(part, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(line.strip()[i])\n",
    "        path_save = f\"sampleCaptchas/data/{str(counter).rjust(4, '0')}.jpg\"\n",
    "        cv2.imwrite(path_save, part)\n",
    "        data.append([path_save, line.strip()[i]])\n",
    "        counter += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "df = pd.DataFrame(data, columns=['path', 'value'])\n",
    "df.to_csv('sampleCaptchas/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb43d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d00ccb8",
   "metadata": {},
   "source": [
    "# Create CNN model to classify characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characters mapping\n",
    "CHARS = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "char_to_idx = {c: i for i, c in enumerate(CHARS)}\n",
    "idx_to_char = {i: c for i, c in enumerate(CHARS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77445d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        label_char = self.data.iloc[idx, 1]\n",
    "        label = char_to_idx[label_char]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=len(CHARS)):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  \n",
    "        x = F.relu(self.conv2(x))  \n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f178e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Prepare dataset and dataloader\n",
    "dataset = CaptchaDataset(csv_file='sampleCaptchas/data.csv', root_dir='', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd9c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b1a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'captcha_model.pth')\n",
    "\n",
    "print(\"Training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403ed9d",
   "metadata": {},
   "source": [
    "# Perform Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_character(image_path, model_path='captcha_model.pth'):\n",
    "    # Load model\n",
    "    model = SimpleCNN()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    input_tensor = transform(image).unsqueeze(0)  # add batch dimension\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        pred_idx = output.argmax(dim=1).item()\n",
    "        predicted_char = idx_to_char[pred_idx]\n",
    "\n",
    "    return predicted_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24133a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_character('sampleCaptchas/input/input00.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file_path = 'sampleCaptchas/output/'\n",
    "\n",
    "counter = 1\n",
    "data = []\n",
    "for img_name in image_files:\n",
    "    print(img_name)\n",
    "    text_file = img_name.replace('jpg', 'txt').replace('input', 'output')\n",
    "    with open(text_file_path + text_file, 'r') as f:\n",
    "        for line in f:\n",
    "            print(line.strip())\n",
    "        \n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = crop_image(img, top=11, bottom=9, left=5, right=11)\n",
    "    _, img = cv2.threshold(img, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "    img = cv2.bitwise_not(img)\n",
    "    \n",
    "    parts = slice_left_to_right(img)\n",
    "\n",
    "    # Display the 5 vertical slices\n",
    "    for i, part in enumerate(parts):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(part, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        path_save = f\"sampleCaptchas/data/{str(counter).rjust(4, '0')}.jpg\"\n",
    "        cv2.imwrite(path_save, part)\n",
    "        \n",
    "        pred = predict_character(path_save)\n",
    "        \n",
    "        plt.title(line.strip()[i] + ' -> ' + pred)\n",
    "        data.append([path_save, line.strip()[i], pred])\n",
    "        counter += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "df = pd.DataFrame(data, columns=['path', 'value', 'pred'])\n",
    "df.to_csv('sampleCaptchas/data_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = df['pred']\n",
    "true = df['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500ad84",
   "metadata": {},
   "source": [
    "# Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = len(data)  # where data is list of [path, true_label, pred_label]\n",
    "\n",
    "for _, true_label, pred_label in data:\n",
    "    if true_label == pred_label:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d676903",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = []\n",
    "\n",
    "for path, true_label, pred_label in data:\n",
    "    if true_label != pred_label:\n",
    "        wrong_predictions.append((path, true_label, pred_label))\n",
    "\n",
    "print(f\"Total wrong predictions: {len(wrong_predictions)}\")\n",
    "for item in wrong_predictions:\n",
    "    print(f\"Image: {item[0]}, True: {item[1]}, Predicted: {item[2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e12ea3",
   "metadata": {},
   "source": [
    "# Final deliverable for Captcha Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Captcha(object):\n",
    "    def __init__(self, model_path='captcha_model.pth'):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = SimpleCNN()\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    def predict_character(self, img_array):\n",
    "        \"\"\"Predict single character from numpy grayscale image.\"\"\"\n",
    "        pil_img = Image.fromarray(img_array)\n",
    "        input_tensor = self.transform(pil_img).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)\n",
    "            pred_idx = output.argmax(dim=1).item()\n",
    "            return idx_to_char[pred_idx]\n",
    "\n",
    "    def __call__(self, im_path, save_path):\n",
    "        # Load and preprocess image\n",
    "        img = cv2.imread(im_path)\n",
    "        img = crop_image(img, top=11, bottom=9, left=5, right=11)\n",
    "\n",
    "        # Convert to grayscale if needed\n",
    "        if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            img_gray = img\n",
    "        \n",
    "        _, img_thresh = cv2.threshold(img_gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "        img_inv = cv2.bitwise_not(img_thresh)\n",
    "\n",
    "        # Slice into 5 parts\n",
    "        parts = slice_left_to_right(img_inv, num_parts=5)\n",
    "\n",
    "        predicted_chars = []\n",
    "        for part in parts:\n",
    "            pred_char = self.predict_character(part)\n",
    "            predicted_chars.append(pred_char)\n",
    "        \n",
    "        predicted_text = ''.join(predicted_chars)\n",
    "        \n",
    "        # Save prediction to file\n",
    "        with open(save_path, 'w') as f:\n",
    "            f.write(predicted_text)\n",
    "        \n",
    "        return predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "captcha = Captcha(model_path='captcha_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366bae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = 'sampleCaptchas/input/input01.jpg'\n",
    "output_txt = 'sampleCaptchas/pred/output01.txt'\n",
    "print(captcha('sampleCaptchas/input/input01.jpg', 'sampleCaptchas/pred/output01.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(input_img)\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Convert from BGR to RGB for matplotlib\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(img_name)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04e7a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5ecd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcad8be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
